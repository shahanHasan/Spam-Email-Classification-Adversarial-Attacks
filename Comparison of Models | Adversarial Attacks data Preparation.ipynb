{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "worse-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from utils import *\n",
    "import random\n",
    "\n",
    "#Classifiers \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Time and counters\n",
    "from time import perf_counter\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import f1_score , recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#NLTK\n",
    "import nltk\n",
    "from nltk import flatten , FreqDist\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet   #Import wordnet from the NLTK\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-signal",
   "metadata": {},
   "source": [
    "# Comparison of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "union-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers = pd.read_csv(\"comparison/Metrics_Comparison.csv\")\n",
    "Classifiers = Classifiers.loc[:, ~Classifiers.columns.str.contains('^Unnamed')]\n",
    "Classifiers.to_csv(\"comparison/Metrics_Comparison.csv\", index=False)\n",
    "DNN_Glove = pd.read_csv(\"comparison/DNN_glove_comparison.csv\")\n",
    "DNN_Glove = DNN_Glove.loc[:, ~DNN_Glove.columns.str.contains('^Unnamed')]\n",
    "DNN_Glove.to_csv(\"comparison/DNN_glove_comparison.csv\", index=False)\n",
    "DNN = pd.read_csv(\"comparison/DNN_Trainable_Embeddings_comparison.csv\")\n",
    "DNN = DNN.loc[:, ~DNN.columns.str.contains('^Unnamed')]\n",
    "DNN.to_csv(\"comparison/DNN_Trainable_Embeddings_comparison.csv\", index=False)\n",
    "\n",
    "DNN_Glove_2 = pd.read_csv(\"comparison/DNN_glove_2_comparison.csv\")\n",
    "DNN_Glove_2 = DNN_Glove_2.loc[:, ~DNN_Glove_2.columns.str.contains('^Unnamed')]\n",
    "DNN_Glove_2.to_csv(\"comparison/DNN_glove_2_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "regular-atmosphere",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Training time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.984398</td>\n",
       "      <td>0.989835</td>\n",
       "      <td>0.987075</td>\n",
       "      <td>0.989991</td>\n",
       "      <td>0.989835</td>\n",
       "      <td>18.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.986752</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.983343</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.987905</td>\n",
       "      <td>0.978924</td>\n",
       "      <td>0.983305</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>0.978924</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regr.</td>\n",
       "      <td>0.986108</td>\n",
       "      <td>0.964420</td>\n",
       "      <td>0.974630</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>0.964420</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.981635</td>\n",
       "      <td>0.945804</td>\n",
       "      <td>0.961995</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>0.945804</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>0.944477</td>\n",
       "      <td>0.957408</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.944477</td>\n",
       "      <td>24.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.960225</td>\n",
       "      <td>0.941921</td>\n",
       "      <td>0.950586</td>\n",
       "      <td>0.962693</td>\n",
       "      <td>0.941921</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.968443</td>\n",
       "      <td>0.927610</td>\n",
       "      <td>0.945718</td>\n",
       "      <td>0.959964</td>\n",
       "      <td>0.927610</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.935225</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.831223</td>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Precision    Recall  f1 score  Accuracy   ROC-AUC  \\\n",
       "0            XGBoost   0.984398  0.989835  0.987075  0.989991  0.989835   \n",
       "1       SVM (Linear)   0.986752  0.980057  0.983343  0.987261  0.980057   \n",
       "2          SVM (RBF)   0.987905  0.978924  0.983305  0.987261  0.978924   \n",
       "3     Logistic Regr.   0.986108  0.964420  0.974630  0.980892  0.964420   \n",
       "4      Random Forest   0.981635  0.945804  0.961995  0.971793  0.945804   \n",
       "5  Gradient Boosting   0.972522  0.944477  0.957408  0.968153  0.944477   \n",
       "6      Decision Tree   0.960225  0.941921  0.950586  0.962693  0.941921   \n",
       "7                KNN   0.968443  0.927610  0.945718  0.959964  0.927610   \n",
       "8      MultinomialNB   0.935225  0.788462  0.831223  0.889900  0.788462   \n",
       "\n",
       "   Training time (sec)  \n",
       "0                18.89  \n",
       "1                 0.10  \n",
       "2                15.33  \n",
       "3                 2.16  \n",
       "4                 7.06  \n",
       "5                24.77  \n",
       "6                 2.92  \n",
       "7                 0.03  \n",
       "8                 0.02  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "organic-friend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>Loss</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cnn with word embeddings</td>\n",
       "      <td>0.988799</td>\n",
       "      <td>0.989353</td>\n",
       "      <td>0.989911</td>\n",
       "      <td>0.991811</td>\n",
       "      <td>0.818926</td>\n",
       "      <td>0.046117</td>\n",
       "      <td>0.988799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ann with word embeddings</td>\n",
       "      <td>0.987472</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.982061</td>\n",
       "      <td>0.988171</td>\n",
       "      <td>1.182896</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.987472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rnn with word embeddings</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>0.977209</td>\n",
       "      <td>0.984820</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>1.728845</td>\n",
       "      <td>0.083168</td>\n",
       "      <td>0.970183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Precision    Recall  f1 score  Accuracy  \\\n",
       "0  Cnn with word embeddings   0.988799  0.989353  0.989911  0.991811   \n",
       "1  Ann with word embeddings   0.987472  0.984725  0.982061  0.988171   \n",
       "2  Rnn with word embeddings   0.970183  0.977209  0.984820  0.982712   \n",
       "\n",
       "      Error      Loss   ROC-AUC  \n",
       "0  0.818926  0.046117  0.988799  \n",
       "1  1.182896  0.030170  0.987472  \n",
       "2  1.728845  0.083168  0.970183  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "occupied-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>Loss</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rnn with GLOVE embeddings</td>\n",
       "      <td>0.861729</td>\n",
       "      <td>0.882229</td>\n",
       "      <td>0.910450</td>\n",
       "      <td>0.914468</td>\n",
       "      <td>8.553231</td>\n",
       "      <td>0.223910</td>\n",
       "      <td>0.861729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ann with GLOVE embeddings</td>\n",
       "      <td>0.910071</td>\n",
       "      <td>0.886088</td>\n",
       "      <td>0.869484</td>\n",
       "      <td>0.907188</td>\n",
       "      <td>9.281164</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.910071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cnn with GLOVE embeddings</td>\n",
       "      <td>0.832914</td>\n",
       "      <td>0.864220</td>\n",
       "      <td>0.917684</td>\n",
       "      <td>0.905369</td>\n",
       "      <td>9.463149</td>\n",
       "      <td>0.212180</td>\n",
       "      <td>0.832914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Precision    Recall  f1 score  Accuracy  \\\n",
       "0  Rnn with GLOVE embeddings   0.861729  0.882229  0.910450  0.914468   \n",
       "1  Ann with GLOVE embeddings   0.910071  0.886088  0.869484  0.907188   \n",
       "2  Cnn with GLOVE embeddings   0.832914  0.864220  0.917684  0.905369   \n",
       "\n",
       "      Error      Loss   ROC-AUC  \n",
       "0  8.553231  0.223910  0.861729  \n",
       "1  9.281164  0.234421  0.910071  \n",
       "2  9.463149  0.212180  0.832914  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN_Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "attached-property",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>Loss</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cnn with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.971544</td>\n",
       "      <td>0.969416</td>\n",
       "      <td>0.967339</td>\n",
       "      <td>0.976342</td>\n",
       "      <td>2.365786</td>\n",
       "      <td>0.271382</td>\n",
       "      <td>0.971544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rnn with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.852532</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.922657</td>\n",
       "      <td>7.734305</td>\n",
       "      <td>0.322624</td>\n",
       "      <td>0.852532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ann with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.730672</td>\n",
       "      <td>0.771247</td>\n",
       "      <td>0.909531</td>\n",
       "      <td>0.858053</td>\n",
       "      <td>14.194721</td>\n",
       "      <td>0.350729</td>\n",
       "      <td>0.730672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Precision    Recall  f1 score  \\\n",
       "0  Cnn with GLOVE embeddings architecture 2   0.971544  0.969416  0.967339   \n",
       "1  Rnn with GLOVE embeddings architecture 2   0.852532  0.888220  0.950662   \n",
       "2  Ann with GLOVE embeddings architecture 2   0.730672  0.771247  0.909531   \n",
       "\n",
       "   Accuracy      Error      Loss   ROC-AUC  \n",
       "0  0.976342   2.365786  0.271382  0.971544  \n",
       "1  0.922657   7.734305  0.322624  0.852532  \n",
       "2  0.858053  14.194721  0.350729  0.730672  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN_Glove_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "instrumental-chuck",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>Loss</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cnn with word embeddings</td>\n",
       "      <td>0.988799</td>\n",
       "      <td>0.989353</td>\n",
       "      <td>0.989911</td>\n",
       "      <td>0.991811</td>\n",
       "      <td>0.818926</td>\n",
       "      <td>0.046117</td>\n",
       "      <td>0.988799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ann with word embeddings</td>\n",
       "      <td>0.987472</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.982061</td>\n",
       "      <td>0.988171</td>\n",
       "      <td>1.182896</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.987472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rnn with word embeddings</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>0.977209</td>\n",
       "      <td>0.984820</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>1.728845</td>\n",
       "      <td>0.083168</td>\n",
       "      <td>0.970183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rnn with GLOVE embeddings</td>\n",
       "      <td>0.861729</td>\n",
       "      <td>0.882229</td>\n",
       "      <td>0.910450</td>\n",
       "      <td>0.914468</td>\n",
       "      <td>8.553231</td>\n",
       "      <td>0.223910</td>\n",
       "      <td>0.861729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ann with GLOVE embeddings</td>\n",
       "      <td>0.910071</td>\n",
       "      <td>0.886088</td>\n",
       "      <td>0.869484</td>\n",
       "      <td>0.907188</td>\n",
       "      <td>9.281164</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.910071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cnn with GLOVE embeddings</td>\n",
       "      <td>0.832914</td>\n",
       "      <td>0.864220</td>\n",
       "      <td>0.917684</td>\n",
       "      <td>0.905369</td>\n",
       "      <td>9.463149</td>\n",
       "      <td>0.212180</td>\n",
       "      <td>0.832914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cnn with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.971544</td>\n",
       "      <td>0.969416</td>\n",
       "      <td>0.967339</td>\n",
       "      <td>0.976342</td>\n",
       "      <td>2.365786</td>\n",
       "      <td>0.271382</td>\n",
       "      <td>0.971544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rnn with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.852532</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.922657</td>\n",
       "      <td>7.734305</td>\n",
       "      <td>0.322624</td>\n",
       "      <td>0.852532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ann with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.730672</td>\n",
       "      <td>0.771247</td>\n",
       "      <td>0.909531</td>\n",
       "      <td>0.858053</td>\n",
       "      <td>14.194721</td>\n",
       "      <td>0.350729</td>\n",
       "      <td>0.730672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Precision    Recall  f1 score  \\\n",
       "0                  Cnn with word embeddings   0.988799  0.989353  0.989911   \n",
       "1                  Ann with word embeddings   0.987472  0.984725  0.982061   \n",
       "2                  Rnn with word embeddings   0.970183  0.977209  0.984820   \n",
       "0                 Rnn with GLOVE embeddings   0.861729  0.882229  0.910450   \n",
       "1                 Ann with GLOVE embeddings   0.910071  0.886088  0.869484   \n",
       "2                 Cnn with GLOVE embeddings   0.832914  0.864220  0.917684   \n",
       "0  Cnn with GLOVE embeddings architecture 2   0.971544  0.969416  0.967339   \n",
       "1  Rnn with GLOVE embeddings architecture 2   0.852532  0.888220  0.950662   \n",
       "2  Ann with GLOVE embeddings architecture 2   0.730672  0.771247  0.909531   \n",
       "\n",
       "   Accuracy      Error      Loss   ROC-AUC  \n",
       "0  0.991811   0.818926  0.046117  0.988799  \n",
       "1  0.988171   1.182896  0.030170  0.987472  \n",
       "2  0.982712   1.728845  0.083168  0.970183  \n",
       "0  0.914468   8.553231  0.223910  0.861729  \n",
       "1  0.907188   9.281164  0.234421  0.910071  \n",
       "2  0.905369   9.463149  0.212180  0.832914  \n",
       "0  0.976342   2.365786  0.271382  0.971544  \n",
       "1  0.922657   7.734305  0.322624  0.852532  \n",
       "2  0.858053  14.194721  0.350729  0.730672  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merged = [DNN , DNN_Glove, DNN_Glove_2]\n",
    "Merged = pd.concat(Merged)\n",
    "Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "diagnostic-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Columns \n",
    "Merged_drop = Merged.drop(columns=[\"Error\", \"Loss\"], axis=1).copy()\n",
    "Classifiers_drop = Classifiers.drop(columns=[\"Training time (sec)\"],axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "indie-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_comparison = [Classifiers_drop , Merged_drop]\n",
    "Full_comparison = pd.concat(Full_comparison).sort_values(by=['Accuracy'],ascending=False)\n",
    "Full_comparison.to_csv('comparison/All_models_and_classifiers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sufficient-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cnn with word embeddings</td>\n",
       "      <td>0.988799</td>\n",
       "      <td>0.989353</td>\n",
       "      <td>0.989911</td>\n",
       "      <td>0.991811</td>\n",
       "      <td>0.988799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.984398</td>\n",
       "      <td>0.989835</td>\n",
       "      <td>0.987075</td>\n",
       "      <td>0.989991</td>\n",
       "      <td>0.989835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ann with word embeddings</td>\n",
       "      <td>0.987472</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.982061</td>\n",
       "      <td>0.988171</td>\n",
       "      <td>0.987472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.987905</td>\n",
       "      <td>0.978924</td>\n",
       "      <td>0.983305</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>0.978924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.986752</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.983343</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>0.980057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rnn with word embeddings</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>0.977209</td>\n",
       "      <td>0.984820</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>0.970183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regr.</td>\n",
       "      <td>0.986108</td>\n",
       "      <td>0.964420</td>\n",
       "      <td>0.974630</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>0.964420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cnn with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.971544</td>\n",
       "      <td>0.969416</td>\n",
       "      <td>0.967339</td>\n",
       "      <td>0.976342</td>\n",
       "      <td>0.971544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.981635</td>\n",
       "      <td>0.945804</td>\n",
       "      <td>0.961995</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>0.945804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>0.944477</td>\n",
       "      <td>0.957408</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.944477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.960225</td>\n",
       "      <td>0.941921</td>\n",
       "      <td>0.950586</td>\n",
       "      <td>0.962693</td>\n",
       "      <td>0.941921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.968443</td>\n",
       "      <td>0.927610</td>\n",
       "      <td>0.945718</td>\n",
       "      <td>0.959964</td>\n",
       "      <td>0.927610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rnn with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.852532</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.922657</td>\n",
       "      <td>0.852532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rnn with GLOVE embeddings</td>\n",
       "      <td>0.861729</td>\n",
       "      <td>0.882229</td>\n",
       "      <td>0.910450</td>\n",
       "      <td>0.914468</td>\n",
       "      <td>0.861729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ann with GLOVE embeddings</td>\n",
       "      <td>0.910071</td>\n",
       "      <td>0.886088</td>\n",
       "      <td>0.869484</td>\n",
       "      <td>0.907188</td>\n",
       "      <td>0.910071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cnn with GLOVE embeddings</td>\n",
       "      <td>0.832914</td>\n",
       "      <td>0.864220</td>\n",
       "      <td>0.917684</td>\n",
       "      <td>0.905369</td>\n",
       "      <td>0.832914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.935225</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.831223</td>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ann with GLOVE embeddings architecture 2</td>\n",
       "      <td>0.730672</td>\n",
       "      <td>0.771247</td>\n",
       "      <td>0.909531</td>\n",
       "      <td>0.858053</td>\n",
       "      <td>0.730672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Model  Precision    Recall  f1 score  \\\n",
       "0                   Cnn with word embeddings   0.988799  0.989353  0.989911   \n",
       "1                                    XGBoost   0.984398  0.989835  0.987075   \n",
       "2                   Ann with word embeddings   0.987472  0.984725  0.982061   \n",
       "3                                  SVM (RBF)   0.987905  0.978924  0.983305   \n",
       "4                               SVM (Linear)   0.986752  0.980057  0.983343   \n",
       "5                   Rnn with word embeddings   0.970183  0.977209  0.984820   \n",
       "6                             Logistic Regr.   0.986108  0.964420  0.974630   \n",
       "7   Cnn with GLOVE embeddings architecture 2   0.971544  0.969416  0.967339   \n",
       "8                              Random Forest   0.981635  0.945804  0.961995   \n",
       "9                          Gradient Boosting   0.972522  0.944477  0.957408   \n",
       "10                             Decision Tree   0.960225  0.941921  0.950586   \n",
       "11                                       KNN   0.968443  0.927610  0.945718   \n",
       "12  Rnn with GLOVE embeddings architecture 2   0.852532  0.888220  0.950662   \n",
       "13                 Rnn with GLOVE embeddings   0.861729  0.882229  0.910450   \n",
       "14                 Ann with GLOVE embeddings   0.910071  0.886088  0.869484   \n",
       "15                 Cnn with GLOVE embeddings   0.832914  0.864220  0.917684   \n",
       "16                             MultinomialNB   0.935225  0.788462  0.831223   \n",
       "17  Ann with GLOVE embeddings architecture 2   0.730672  0.771247  0.909531   \n",
       "\n",
       "    Accuracy   ROC-AUC  \n",
       "0   0.991811  0.988799  \n",
       "1   0.989991  0.989835  \n",
       "2   0.988171  0.987472  \n",
       "3   0.987261  0.978924  \n",
       "4   0.987261  0.980057  \n",
       "5   0.982712  0.970183  \n",
       "6   0.980892  0.964420  \n",
       "7   0.976342  0.971544  \n",
       "8   0.971793  0.945804  \n",
       "9   0.968153  0.944477  \n",
       "10  0.962693  0.941921  \n",
       "11  0.959964  0.927610  \n",
       "12  0.922657  0.852532  \n",
       "13  0.914468  0.861729  \n",
       "14  0.907188  0.910071  \n",
       "15  0.905369  0.832914  \n",
       "16  0.889900  0.788462  \n",
       "17  0.858053  0.730672  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_comparison = pd.read_csv(\"comparison/All_models_and_classifiers.csv\")\n",
    "# All_comparison = All_comparison.loc[:, ~All_comparison.columns.str.contains('^Unnamed')]\n",
    "All_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "played-allen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>leaf_size</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973388</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973388</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973388</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973388</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973388</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.804139</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.804139</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.804139</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.804139</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.804139</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  leaf_size  n_neighbors  p\n",
       "0          0.973388         20            5  2\n",
       "1          0.973388          5            5  2\n",
       "2          0.973388         25            5  2\n",
       "3          0.973388         30            5  2\n",
       "4          0.973388         10            5  2\n",
       "..              ...        ...          ... ..\n",
       "67         0.804139         20           30  1\n",
       "68         0.804139          5           30  1\n",
       "69         0.804139         10           30  1\n",
       "70         0.804139         15           30  1\n",
       "71         0.804139         30           30  1\n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_hyperparameters_tuned = pd.read_csv(\"comparison/KNN_hyperparameters.csv\")\n",
    "KNN_hyperparameters_tuned = KNN_hyperparameters_tuned.loc[:, ~KNN_hyperparameters_tuned.columns.str.contains('^Unnamed')]\n",
    "KNN_hyperparameters_tuned.to_csv(\"comparison/KNN_hyperparameters.csv\", index=False)\n",
    "KNN_hyperparameters_tuned.params = KNN_hyperparameters_tuned.params.apply(eval)\n",
    "KNN_hyperparameters_tuned = pd.concat([KNN_hyperparameters_tuned.drop(['params'], axis=1), KNN_hyperparameters_tuned['params'].apply(pd.Series)], axis=1)\n",
    "KNN_hyperparameters_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "colonial-princess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = KNN_hyperparameters_tuned.mean_test_score\n",
    "y = KNN_hyperparameters_tuned.p\n",
    "z = KNN_hyperparameters_tuned.n_neighbors\n",
    "c = KNN_hyperparameters_tuned.leaf_size\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-highway",
   "metadata": {},
   "source": [
    "# Adversarial Attacks\n",
    "\n",
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "combined-glance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "MultinomialNB\n",
      "Logistic Regr.\n",
      "KNN\n",
      "Decision Tree\n",
      "SVM (Linear)\n",
      "SVM (RBF)\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": {\"model\":0},\n",
    "    \"Gradient Boosting\": {\"model\":0},\n",
    "    \"XGBoost\": {\"model\":0},\n",
    "    \"MultinomialNB\": {\"model\":0},\n",
    "    \"Logistic Regr.\": {\"model\":0},\n",
    "    \"KNN\": {\"model\":0},\n",
    "    \"Decision Tree\": {\"model\":0},\n",
    "    \"SVM (Linear)\": {\"model\":0},\n",
    "    \"SVM (RBF)\": {\"model\":0}\n",
    "}\n",
    "\n",
    "filenames = [\"Random_forest.pkl\" , \"Gradient_Boosting.pkl\" , \"XGBoost.pkl\" , \"MultinomialNB.pkl\" , \"Logistic_regression.pkl\" ,\n",
    "            \"KNN.pkl\" , \"Decision_tree.pkl\" , \"SVM_linear.pkl\" , \"SVM_RBF.pkl\"]\n",
    "index = 0\n",
    "for name, model in models.items():\n",
    "    print(name) \n",
    "    with open(f\"comparison/classifiers/{filenames[index]}\", \"rb\") as open_file:\n",
    "        model[\"model\"] = pickle.load(open_file)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "final-institute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree': {'model': DecisionTreeClassifier()},\n",
      " 'Gradient Boosting': {'model': GradientBoostingClassifier()},\n",
      " 'KNN': {'model': KNeighborsClassifier()},\n",
      " 'Logistic Regr.': {'model': LogisticRegression()},\n",
      " 'MultinomialNB': {'model': MultinomialNB(alpha=0.2)},\n",
      " 'Random Forest': {'model': RandomForestClassifier()},\n",
      " 'SVM (Linear)': {'model': LinearSVC()},\n",
      " 'SVM (RBF)': {'model': SVC()},\n",
      " 'XGBoost': {'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='mlogloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "comfortable-beaver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dictionery : 5\n",
      "type of the dictionery : <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open(f\"comparison/classifiers/train_test_tf_idf.pkl\", \"rb\") as open_file:\n",
    "    dataset_processed = pickle.load(open_file)\n",
    "\n",
    "length  = len(dataset_processed)\n",
    "type_ = type(dataset_processed)\n",
    "\n",
    "print(f\"length of the dictionery : {len(dataset_processed)}\")\n",
    "print(f\"type of the dictionery : {type(dataset_processed)}\")\n",
    "\n",
    "assert length == 5\n",
    "assert type_ == dict\n",
    "\n",
    "X_train, X_test, y_train, y_test , tfidf = dataset_processed[\"X_train\"] , dataset_processed[\"X_test\"] , \\\n",
    "        dataset_processed[\"y_train\"] , dataset_processed[\"y_test\"] , dataset_processed[\"tf-idf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "increasing-conservative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 28165)\n",
      "Testomg data shape : (1099, 28165)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training split input: {X_train.shape}\")\n",
    "print(f\"Testing split input : {X_test.shape}\")\n",
    "print(f\"Training split class: {y_train.shape}\")\n",
    "print(f\"Testing split class : {y_test.shape}\")\n",
    "\n",
    "# Get feature names in the vector\n",
    "# tfidf.get_feature_names()\n",
    "\n",
    "X_train_vect = tfidf.fit_transform(X_train)\n",
    "X_test_vect = tfidf.transform(X_test)\n",
    "\n",
    "# Get feature names in the vector\n",
    "#tfidf.get_feature_names()\n",
    "\n",
    "X_train_vect.toarray()\n",
    "print(f\"Training data shape : {X_train_vect.shape}\")\n",
    "X_test_vect.toarray()\n",
    "print(f\"Testomg data shape : {X_test_vect.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dried-cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split class type: <class 'pandas.core.series.Series'>\n",
      "Testing split class type : <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training split class type: {type(y_train)}\")\n",
    "print(f\"Testing split class type : {type(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-timber",
   "metadata": {},
   "source": [
    "# **Algorithm 1: Label Flip Algorithm.**\n",
    "\n",
    "\n",
    "### 1. set a threshold of 10% 15% 20% 25% \n",
    "### 2. Make 4 train dataset with X% relabeled data both spam and ham\n",
    "### 3. Train classifier with the train data\n",
    "### 4. Evaluate the classifier with test data\n",
    "### 5. Get performance metrics like , f1score , precision, recall, confusion matrix heatmap\n",
    "\n",
    "\n",
    "\n",
    "```C\n",
    "Parameters: \n",
    "threshold = [list of percentage], y_train, \n",
    "idx_all (randomly generated indexes for all threshold)\n",
    "Results = {}\n",
    "\n",
    "Input: training set T = xi,yi \n",
    "\n",
    "for i in threshold:\n",
    "    indexes_for_threshold_i = idx_all[i]\n",
    "    for j in indexes_for_threshold_i:\n",
    "        y_train[j] ~= 1 #Bit flip\n",
    "    \n",
    "    model.fit(xi,y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    y_pred = model.predict(predict)\n",
    "    Results[\"y_train\"] = y_train\n",
    "    Results[\"test_accuracy\"] = test_accuracy\n",
    "    Results[\"y_pred\"] = y_pred\n",
    "        \n",
    "\n",
    "Output: Results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "compatible-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training split class type: <class 'pandas.core.series.Series'>\n",
      "Testing split class type : <class 'pandas.core.series.Series'>\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Training split input: {X_train.shape}\")\n",
    "print(f\"Testing split input : {X_test.shape}\")\n",
    "print(f\"Training split class: {y_train.shape}\")\n",
    "print(f\"Testing split class : {y_test.shape}\")\n",
    "\n",
    "print(f\"Training split class type: {type(y_train)}\")\n",
    "print(f\"Testing split class type : {type(y_test)}\")\n",
    "\n",
    "y_train_np = np.asarray(y_train).astype(\"float32\").copy()\n",
    "y_test_np = np.asarray(y_test).astype(\"float32\").copy()\n",
    "\n",
    "\n",
    "print(f\"Training split class: {y_train_np.shape}\")\n",
    "print(f\"Testing split class : {y_test_np.shape}\")\n",
    "print(f\"Training split class type: {type(y_train_np)}\")\n",
    "print(f\"Testing split class type : {type(y_test_np)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "provincial-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records being relabeled based on threshold (%) : [10, 12, 15, 17, 20] is numbers : [440, 528, 659, 747, 879]\n"
     ]
    }
   ],
   "source": [
    "assert len(X_train) == len(y_train)\n",
    "thresholds = [10, 12, 15, 17, 20]\n",
    "train_length = len(X_train)\n",
    "num = [round(train_length * i / 100) for i in thresholds]\n",
    "print(f\"Number of records being relabeled based on threshold (%) : {thresholds} is numbers : {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "alleged-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "y_train_relabeled = y_train_np.copy()\n",
    "\n",
    "idx_all = []\n",
    "for i in num:\n",
    "    idx = np.random.randint(train_length, size = i)\n",
    "    idx_all.append(idx)\n",
    "\n",
    "assert len(idx_all[0]) == 440\n",
    "assert len(idx_all[1]) == 528\n",
    "assert len(idx_all[2]) == 659\n",
    "assert len(idx_all[3]) == 747\n",
    "assert len(idx_all[4]) == 879\n",
    "assert len(idx_all) == len(thresholds)\n",
    "# print(idx_all[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "reflected-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "devoted-mistake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 %</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>10.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 %</td>\n",
       "      <td>0.940855</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15 %</td>\n",
       "      <td>0.873521</td>\n",
       "      <td>15.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17 %</td>\n",
       "      <td>0.829845</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 %</td>\n",
       "      <td>0.725205</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Threshold  Accuracy  Duration\n",
       "0      10 %  0.961783     10.94\n",
       "1      12 %  0.940855     11.67\n",
       "2      15 %  0.873521     15.30\n",
       "3      17 %  0.829845     10.53\n",
       "4      20 %  0.725205     12.07"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Poisoned_classifiers = {\n",
    "    \"10 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data_label\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"12 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data_label\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"15 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data_label\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"17 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data_label\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"20 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data_label\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \n",
    "}\n",
    "\n",
    "for i, v in enumerate(Poisoned_classifiers):\n",
    "    list_of_index = idx_all[i]\n",
    "    start = perf_counter()\n",
    "    for j in list_of_index:\n",
    "        if y_train_relabeled[j] == 1.0:\n",
    "            y_train_relabeled[j] = 0.0\n",
    "        else :\n",
    "            y_train_relabeled[j] = 1.0\n",
    "    \n",
    "    Poisoned_classifiers[v][\"model\"].fit(X_train_vect, y_train_relabeled)\n",
    "    test_accuracy = Poisoned_classifiers[v][\"model\"].score(X_test_vect, y_test_np)\n",
    "    y_pred = Poisoned_classifiers[v][\"model\"].predict(X_test_vect)\n",
    "    duration = perf_counter() - start\n",
    "    duration = round(duration,2)\n",
    "    Poisoned_classifiers[v][\"train_data_label\"] = y_train_relabeled\n",
    "    Poisoned_classifiers[v][\"y_pred\"] = y_pred\n",
    "    Poisoned_classifiers[v][\"duration\"] = duration\n",
    "    Poisoned_classifiers[v][\"accuracy\"] = test_accuracy\n",
    "\n",
    "    \n",
    "model_information = []\n",
    "\n",
    "for percent,model in Poisoned_classifiers.items():\n",
    "    model_information.append([percent, model[\"accuracy\"], model[\"duration\"]])\n",
    "    \n",
    "info = pd.DataFrame(model_information)\n",
    "info.columns = [\"Threshold\" , \"Accuracy\", \"Duration\"]\n",
    "info.sort_values(by = 'Accuracy', ascending = False, inplace=True)\n",
    "info.reset_index(drop = True, inplace=True)\n",
    "info.to_csv(\"comparison/Label_flip_Adversarial.csv\")\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-combine",
   "metadata": {},
   "source": [
    "# Actual accuracy : 98.99 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "serious-efficiency",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-03ff6fbff027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_relabeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.array_equal(y_train_np, y_train_relabeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-vector",
   "metadata": {},
   "source": [
    "# Algorithm 2 : \n",
    "\n",
    "## 1. Augment emails with synonyms in a certain number of records indexed randomly and derived from a threshold\n",
    "\n",
    "```python\n",
    "Parameters: threshold, index_all_thresholds, get_syn(), X_train\n",
    "\n",
    "Input: Dataset D = (xi,yi) , Results = {}\n",
    "\n",
    "for i in threshold:\n",
    "    index_threshold_i = index_all_thresholds[i]\n",
    "    \n",
    "    for j in index_threshold_i:\n",
    "        text = X_train[j]\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for k in text:\n",
    "            syn = get_synonyms(k)\n",
    "            word = pick_syn(k,syn)\n",
    "            new_text.append(word)\n",
    "        new_text = \" \".join(w for w in new_text)\n",
    "        X_train[j] = new_text\n",
    "        \n",
    "    model.fit(X_train,y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    y_pred = model.predict(predict)\n",
    "    Results[\"X_train\"] = X_train\n",
    "    Results[\"test_accuracy\"] = test_accuracy\n",
    "    Results[\"y_pred\"] = y_pred\n",
    "\n",
    "Output: Results;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "curious-falls",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naturally irresistible corporate identity real...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stock trading gunslinger fanny merrill muzo co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unbelievable home made easy wanting show homeo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>color printing special request additional info...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>money software software compatibility great gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X  spam\n",
       "0  naturally irresistible corporate identity real...     1\n",
       "1  stock trading gunslinger fanny merrill muzo co...     1\n",
       "2  unbelievable home made easy wanting show homeo...     1\n",
       "3  color printing special request additional info...     1\n",
       "4  money software software compatibility great gr...     1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv(\"Augmented_emails.csv\")\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "civil-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Spam words : 16310\n",
      "Top 5 Spam words : ['company', 'business', 'email', 'information', 'money']\n"
     ]
    }
   ],
   "source": [
    "Only_Spam = emails.loc[emails[\"spam\"] != 0]\n",
    "# X_list, X_flattened, Total_num_of_all_words, Total_num_all_distinct_words, Most_Common_Spam_Words = Get_Flattened_list(Only_Spam, num=0)\n",
    "word_list = Only_Spam['X'].str.cat().split(\" \")\n",
    "common_words_freq = Counter(word_list).most_common()\n",
    "\n",
    "# Using map for 0 index\n",
    "common_spam_words = list(map(lambda x: x[0], common_words_freq))\n",
    "# common_words = pd.Series(' '.join(Only_Spam['X']).str.split()).value_counts()\n",
    "print(f\"Total number of Spam words : {len(common_spam_words)}\")\n",
    "print(f\"Top 5 Spam words : {common_spam_words[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "artistic-theta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ham words : 26072\n",
      "Top 5 ham words : ['enron', 'vince', '2000', 'kaminski', 'please']\n"
     ]
    }
   ],
   "source": [
    "Only_Ham = emails.loc[emails[\"spam\"] != 1]\n",
    "# X_list, X_flattened, Total_num_of_all_words, Total_num_all_distinct_words, Most_Common_Spam_Words = Get_Flattened_list(Only_Spam, num=0)\n",
    "word_list = Only_Ham['X'].str.cat().split(\" \")\n",
    "common_words_freq = Counter(word_list).most_common()\n",
    "\n",
    "# Using map for 0 index\n",
    "common_ham_words = list(map(lambda x: x[0], common_words_freq))\n",
    "# common_words = pd.Series(' '.join(Only_Spam['X']).str.split()).value_counts()\n",
    "print(f\"Total number of ham words : {len(common_ham_words)}\")\n",
    "print(f\"Top 5 ham words : {common_ham_words[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "found-timer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The synonyms of the word \"enron\" : \n",
      "[]\n",
      "\n",
      "The synonyms of the word \"vince\" : \n",
      "[]\n",
      "\n",
      "The synonyms of the word \"2000\" : \n",
      "[]\n",
      "\n",
      "The synonyms of the word \"kaminski\" : \n",
      "[]\n",
      "\n",
      "The synonyms of the word \"please\" : \n",
      "['please', 'delight', 'please', 'please', 'please']\n",
      "\n",
      "The synonyms of the word \"company\" : \n",
      "['company', 'company', 'company', 'companionship', 'fellowship', 'society', 'company', 'troupe', 'caller', 'company', 'company', 'party', 'company', \"ship's_company\", 'company', 'company', 'company', 'companion', 'accompany', 'keep_company']\n",
      "\n",
      "The synonyms of the word \"business\" : \n",
      "['business', 'concern', 'business_concern', 'business_organization', 'business_organisation', 'commercial_enterprise', 'business_enterprise', 'business', 'occupation', 'business', 'job', 'line_of_work', 'line', 'business', 'business', 'business', 'business', 'business_sector', 'clientele', 'patronage', 'business', 'business', 'stage_business', 'byplay']\n",
      "\n",
      "The synonyms of the word \"email\" : \n",
      "['electronic_mail', 'e-mail', 'email', 'e-mail', 'email', 'netmail']\n",
      "\n",
      "The synonyms of the word \"information\" : \n",
      "['information', 'info', 'information', 'information', 'data', 'information', 'information', 'selective_information', 'entropy']\n",
      "\n",
      "The synonyms of the word \"money\" : \n",
      "['money', 'money', 'money']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_synonyms(word):\n",
    "    syn = list()\n",
    "    ant = list()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            syn.append(lemma.name())    #add the synonyms\n",
    "            if lemma.antonyms():    #When antonyms are available, add them into the list\n",
    "                ant.append(lemma.antonyms()[0].name())\n",
    "#     print('Synonyms: ' + str(syn))\n",
    "#     print('Antonyms: ' + str(ant))\n",
    "    return syn\n",
    "\n",
    "words = common_ham_words[:5] + common_spam_words[:5]\n",
    "\n",
    "for i in words:\n",
    "    syn = get_synonyms(i)\n",
    "    print(f\"The synonyms of the word \\\"{i}\\\" : \\n{syn}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "hidden-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron\n",
      "companionship\n",
      "delight\n",
      "money\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "def pick_syn(word, syn):\n",
    "    #print(type(word))\n",
    "    \n",
    "    if (len(syn) == 0):\n",
    "        return word\n",
    "    for i in syn:\n",
    "        #print(type(syn[0]))\n",
    "        if(i != word):\n",
    "            return i\n",
    "        else:\n",
    "            continue\n",
    "    return word\n",
    "        \n",
    "\"\"\"\n",
    "Test\n",
    "\"\"\"\n",
    "syn = pick_syn(\"enron\", get_synonyms(\"enron\"))\n",
    "print(syn)\n",
    "\n",
    "syn = pick_syn(\"company\", get_synonyms(\"company\"))\n",
    "print(syn)\n",
    "\n",
    "syn = pick_syn(\"please\", get_synonyms(\"please\"))\n",
    "print(syn)\n",
    "\n",
    "\n",
    "syn = pick_syn(\"money\", get_synonyms(\"money\"))\n",
    "print(syn)\n",
    "\n",
    "a = ['g', 'g', 'g']\n",
    "w = 'g'\n",
    "syn = pick_syn(w,a)\n",
    "print(syn)\n",
    "\n",
    "\n",
    "w = \"please\" \n",
    "s = get_synonyms(\"please\")\n",
    "# print(s)\n",
    "# print(type(w))\n",
    "# print(type(s[0]))\n",
    "assert w == s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "rocky-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records being relabeled based on threshold (%) : [10, 15, 20, 25, 30] is numbers : [440, 659, 879, 1099, 1319]\n"
     ]
    }
   ],
   "source": [
    "thresholds_syn_replacement = [10, 15, 20, 25, 30]\n",
    "train_length = len(X_train)\n",
    "num_records = [round(train_length * i / 100) for i in thresholds_syn_replacement]\n",
    "print(f\"Number of records being relabeled based on threshold (%) : {thresholds_syn_replacement} is numbers : {num_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "valid-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "idx_all_rand = []\n",
    "for i in num_records:\n",
    "    idx = np.random.randint(train_length, size = i)\n",
    "    idx_all_rand.append(idx)\n",
    "\n",
    "assert len(idx_all_rand[0]) == 440\n",
    "assert len(idx_all_rand[1]) == 659\n",
    "assert len(idx_all_rand[2]) == 879\n",
    "assert len(idx_all_rand[3]) == 1099\n",
    "assert len(idx_all_rand[4]) == 1319\n",
    "assert len(idx_all_rand) == len(thresholds_syn_replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cardiovascular-convertible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******** Reporting iteration 0 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 29646)\n",
      "Testing data shape : (1099, 29646)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 1 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 30135)\n",
      "Testing data shape : (1099, 30135)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 2 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 30414)\n",
      "Testing data shape : (1099, 30414)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 3 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 30427)\n",
      "Testing data shape : (1099, 30427)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 4 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 30349)\n",
      "Testing data shape : (1099, 30349)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 %</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>9.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25 %</td>\n",
       "      <td>0.984531</td>\n",
       "      <td>13.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15 %</td>\n",
       "      <td>0.983621</td>\n",
       "      <td>10.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20 %</td>\n",
       "      <td>0.981802</td>\n",
       "      <td>12.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30 %</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>13.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Threshold  Accuracy  Duration\n",
       "0      10 %  0.987261      9.45\n",
       "1      25 %  0.984531     13.37\n",
       "2      15 %  0.983621     10.27\n",
       "3      20 %  0.981802     12.15\n",
       "4      30 %  0.980892     13.41"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Poisoned_classifiers = {\n",
    "    \"10 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"15 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"20 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"25 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"30 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \n",
    "}\n",
    "\n",
    "X_tr = X_train.copy()\n",
    "\n",
    "for i, v in enumerate(Poisoned_classifiers):\n",
    "    list_of_index = idx_all_rand[i]\n",
    "    start = perf_counter()\n",
    "    for j in list_of_index:\n",
    "        text = X_tr[j]\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for k in text:\n",
    "            syn = get_synonyms(k)\n",
    "            word = pick_syn(k,syn)\n",
    "            new_text.append(word)\n",
    "        new_text = \" \".join([w for w in new_text])\n",
    "        X_tr[j] = new_text\n",
    "            \n",
    "    tf_idf_vectorizer = TfidfVectorizer()\n",
    "    X_train_vect = tf_idf_vectorizer.fit_transform(X_tr)\n",
    "    X_test_vect  = tf_idf_vectorizer.transform(X_test)\n",
    "    X_train_vect.toarray()\n",
    "    X_test_vect.toarray()\n",
    "    \n",
    "    print(f\"\\n******** Reporting iteration {i} ********\")\n",
    "    print(f\"Training split input: {X_tr.shape}\")\n",
    "    print(f\"Testing split input : {X_test.shape}\")\n",
    "    print(f\"Training split class: {y_train_np.shape}\")\n",
    "    print(f\"Testing split class : {y_test_np.shape}\")\n",
    "    \n",
    "    print(f\"Training data shape : {X_train_vect.shape}\")\n",
    "    print(f\"Testing data shape : {X_test_vect.shape}\")\n",
    "    \n",
    "    print(f\"Training split class type: {type(y_train_np)}\")\n",
    "    print(f\"Testing split class type : {type(y_test_np)}\\n\")\n",
    "    \n",
    "    \n",
    "    Poisoned_classifiers[v][\"model\"].fit(X_train_vect, y_train_np)\n",
    "    test_accuracy = Poisoned_classifiers[v][\"model\"].score(X_test_vect, y_test_np)\n",
    "    y_pred = Poisoned_classifiers[v][\"model\"].predict(X_test_vect)\n",
    "    duration = perf_counter() - start\n",
    "    duration = round(duration,2)\n",
    "    Poisoned_classifiers[v][\"train_data\"] = X_tr\n",
    "    Poisoned_classifiers[v][\"y_pred\"] = y_pred\n",
    "    Poisoned_classifiers[v][\"duration\"] = duration\n",
    "    Poisoned_classifiers[v][\"accuracy\"] = test_accuracy\n",
    "\n",
    "    \n",
    "model_information = []\n",
    "\n",
    "for percent,model in Poisoned_classifiers.items():\n",
    "    model_information.append([percent, model[\"accuracy\"], model[\"duration\"]])\n",
    "    \n",
    "info = pd.DataFrame(model_information)\n",
    "info.columns = [\"Threshold\" , \"Accuracy\", \"Duration\"]\n",
    "info.sort_values(by = 'Accuracy', ascending = False, inplace=True)\n",
    "info.reset_index(drop = True, inplace=True)\n",
    "info.to_csv(\"comparison/Synonym_Adversarial.csv\")\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-entrance",
   "metadata": {},
   "source": [
    "# Actual accuracy : 98.99 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-aaron",
   "metadata": {},
   "source": [
    "## 2. Augment emails with Ham or Spam words in a certain number of records indexed randomly and derived from a threshold / HAM or SPAM word Injection\n",
    "\n",
    "```python\n",
    "Parameters: \n",
    "threshold, index_all_thresholds, ham_words, spam_words, X_train\n",
    "\n",
    "\n",
    "Input: Dataset D = (xi,yi) , Results = {}\n",
    "\n",
    "for i in threshold:\n",
    "    index_threshold_i = index_all_thresholds[i]\n",
    "    \n",
    "    for j in index_threshold_i:\n",
    "        \n",
    "        if (y_train[j] == 1): #Spam\n",
    "            text = X_train[j]\n",
    "            text = text.split()\n",
    "            Number_of_words_to_add = random.randint(Mean_Length_of_Email, 10)\n",
    "            for k in Number_of_words_to_add:\n",
    "                text.append(ham_words[k])\n",
    "            text = \" \".join([w for w in text])\n",
    "            X_train[j] = new_text\n",
    "        else : #Ham\n",
    "            \n",
    "            text = X_train[j]\n",
    "            text = text.split()\n",
    "            Number_of_words_to_add = random.randint(Mean_Length_of_Email, 10)\n",
    "            for k in Number_of_words_to_add:\n",
    "                text.append(ham_words[k])\n",
    "            text = \" \".join([w for w in text])\n",
    "            X_train[j] = new_text\n",
    "        \n",
    "    model.fit(X_train,y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    y_pred = model.predict(predict)\n",
    "    Results[\"X_train\"] = X_train\n",
    "    Results[\"test_accuracy\"] = test_accuracy\n",
    "    Results[\"y_pred\"] = y_pred\n",
    "\n",
    "Output: Results;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "preliminary-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records being relabeled based on threshold (%) : [20, 25, 30, 35, 40] is numbers : [879, 1099, 1319, 1539, 1758]\n"
     ]
    }
   ],
   "source": [
    "thresholds_spam_ham_replacement = [20, 25, 30, 35, 40]\n",
    "train_length = len(X_train)\n",
    "num_records = [round(train_length * i / 100) for i in thresholds_spam_ham_replacement]\n",
    "print(f\"Number of records being relabeled based on threshold (%) : {thresholds_spam_ham_replacement} is numbers : {num_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "governing-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "idx_all_rand = []\n",
    "for i in num_records:\n",
    "    idx = np.random.randint(train_length, size = i)\n",
    "    idx_all_rand.append(idx)\n",
    "\n",
    "assert len(idx_all_rand[0]) == 879\n",
    "assert len(idx_all_rand[1]) == 1099\n",
    "assert len(idx_all_rand[2]) == 1319\n",
    "assert len(idx_all_rand[3]) == 1539\n",
    "assert len(idx_all_rand[4]) == 1758\n",
    "assert len(idx_all_rand) == len(thresholds_syn_replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "manual-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******** Reporting iteration 0 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 28165)\n",
      "Testing data shape : (1099, 28165)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 1 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 28165)\n",
      "Testing data shape : (1099, 28165)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 2 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 28165)\n",
      "Testing data shape : (1099, 28165)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 3 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 28165)\n",
      "Testing data shape : (1099, 28165)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 4 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 28165)\n",
      "Testing data shape : (1099, 28165)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20 %</td>\n",
       "      <td>0.975432</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25 %</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>11.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35 %</td>\n",
       "      <td>0.964513</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 %</td>\n",
       "      <td>0.963603</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40 %</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>20.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Threshold  Accuracy  Duration\n",
       "0      20 %  0.975432      9.58\n",
       "1      25 %  0.971793     11.72\n",
       "2      35 %  0.964513     14.62\n",
       "3      30 %  0.963603     14.10\n",
       "4      40 %  0.955414     20.29"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randrange, sample\n",
    "\n",
    "def random_insert(lst, item):\n",
    "    lst.insert(randrange(len(lst)+1), item)\n",
    "    \n",
    "Poisoned_classifiers = {\n",
    "    \"20 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"25 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"30 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"35 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \"40 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "    \n",
    "}\n",
    "\n",
    "X_tr = X_train.copy()\n",
    "Mean_Length_of_Email = 400\n",
    "\n",
    "for i, v in enumerate(Poisoned_classifiers):\n",
    "    list_of_index = idx_all_rand[i]\n",
    "    start = perf_counter()\n",
    "    for j in list_of_index:\n",
    "        \n",
    "        if (y_train_np[j] == 1): #Spam\n",
    "            text = X_tr[j]\n",
    "            text = text.split()\n",
    "            num = len(text) - Mean_Length_of_Email\n",
    "            if num < 700 and num > 200:\n",
    "                Number_of_words_to_add = np.random.randint(0, len(common_ham_words[:100]), Mean_Length_of_Email)\n",
    "                for k in Number_of_words_to_add:\n",
    "                    #text.append(common_ham_words[k])\n",
    "                    text.insert(randrange(len(text)+1), common_ham_words[k])\n",
    "            if num < 200:\n",
    "                Number_of_words_to_add = np.random.randint(0, len(common_ham_words[:100]), Mean_Length_of_Email*2)\n",
    "                for k in Number_of_words_to_add:\n",
    "                    #text.append(common_ham_words[k])\n",
    "                    text.insert(randrange(len(text)+1), common_ham_words[k])\n",
    "            if num > 700:\n",
    "                Number_of_words_to_add = np.random.randint(0, len(common_ham_words[:100]), Mean_Length_of_Email)\n",
    "                for k in Number_of_words_to_add:\n",
    "                    #text.append(common_ham_words[k])\n",
    "                    text.insert(randrange(len(text)+1), common_ham_words[k])\n",
    "            text = \" \".join([w for w in text])\n",
    "            X_tr[j] = text\n",
    "        else : #Ham\n",
    "\n",
    "            text = X_tr[j]\n",
    "            text = text.split()\n",
    "            num = len(text) - Mean_Length_of_Email\n",
    "            if num < 700 and num > 200:\n",
    "                Number_of_words_to_add = np.random.randint(0, len(common_spam_words[:100]), Mean_Length_of_Email)\n",
    "                for k in Number_of_words_to_add:\n",
    "                    #text.append(common_spam_words[k])\n",
    "                    text.insert(randrange(len(text)+1), common_spam_words[k])\n",
    "            if num < 200:\n",
    "                Number_of_words_to_add = np.random.randint(low=0, high=len(common_spam_words[:100]), size=Mean_Length_of_Email*2)\n",
    "                for k in Number_of_words_to_add:\n",
    "                    #text.append(common_spam_words[k])\n",
    "                    text.insert(randrange(len(text)+1), common_spam_words[k])\n",
    "            if num > 700:\n",
    "                Number_of_words_to_add = np.random.randint(0, len(common_spam_words[:100]), 100)\n",
    "                for k in Number_of_words_to_add:\n",
    "                    #text.append(common_spam_words[k])\n",
    "                    text.insert(randrange(len(text)+1), common_spam_words[k])\n",
    "            text = \" \".join([w for w in text])\n",
    "            X_tr[j] = text\n",
    "            \n",
    "    tf_idf_vectorizer = TfidfVectorizer()\n",
    "    X_train_vect = tf_idf_vectorizer.fit_transform(X_tr)\n",
    "    X_test_vect  = tf_idf_vectorizer.transform(X_test)\n",
    "    X_train_vect.toarray()\n",
    "    X_test_vect.toarray()\n",
    "    \n",
    "    print(f\"\\n******** Reporting iteration {i} ********\")\n",
    "    print(f\"Training split input: {X_tr.shape}\")\n",
    "    print(f\"Testing split input : {X_test.shape}\")\n",
    "    print(f\"Training split class: {y_train_np.shape}\")\n",
    "    print(f\"Testing split class : {y_test_np.shape}\")\n",
    "    \n",
    "    print(f\"Training data shape : {X_train_vect.shape}\")\n",
    "    print(f\"Testing data shape : {X_test_vect.shape}\")\n",
    "    \n",
    "    print(f\"Training split class type: {type(y_train_np)}\")\n",
    "    print(f\"Testing split class type : {type(y_test_np)}\\n\")\n",
    "    \n",
    "    \n",
    "    Poisoned_classifiers[v][\"model\"].fit(X_train_vect, y_train_np)\n",
    "    test_accuracy = Poisoned_classifiers[v][\"model\"].score(X_test_vect, y_test_np)\n",
    "    y_pred = Poisoned_classifiers[v][\"model\"].predict(X_test_vect)\n",
    "    duration = perf_counter() - start\n",
    "    duration = round(duration,2)\n",
    "    Poisoned_classifiers[v][\"train_data\"] = X_tr\n",
    "    Poisoned_classifiers[v][\"y_pred\"] = y_pred\n",
    "    Poisoned_classifiers[v][\"duration\"] = duration\n",
    "    Poisoned_classifiers[v][\"accuracy\"] = test_accuracy\n",
    "\n",
    "    \n",
    "model_information = []\n",
    "\n",
    "for percent,model in Poisoned_classifiers.items():\n",
    "    model_information.append([percent, model[\"accuracy\"], model[\"duration\"]])\n",
    "    \n",
    "info = pd.DataFrame(model_information)\n",
    "info.columns = [\"Threshold\" , \"Accuracy\", \"Duration\"]\n",
    "info.sort_values(by = 'Accuracy', ascending = False, inplace=True)\n",
    "info.reset_index(drop = True, inplace=True)\n",
    "info.to_csv(\"comparison/Spam_Ham_Injection_random_Adversarial.csv\")\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "naughty-salon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated entries 0\n",
      "duplicated entries 0\n",
      "Number of null features in the dataset :\n",
      "X          0\n",
      "spam       0\n",
      "lengths    0\n",
      "dtype: int64\n",
      "\n",
      "Number of null features in the dataset :\n",
      "X          0\n",
      "spam       0\n",
      "lengths    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5493.000000\n",
       "mean      116.489168\n",
       "std       148.466442\n",
       "min         2.000000\n",
       "25%        39.000000\n",
       "50%        73.000000\n",
       "75%       138.000000\n",
       "max      2469.000000\n",
       "Name: lengths, dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence_tokenized = emails['X'].str.split()\n",
    "# sentence_tokenized.head()\n",
    "#remove duplicated data\n",
    "print(f\"duplicated entries {emails.duplicated().sum()}\")\n",
    "emails = emails.drop_duplicates()\n",
    "print(f\"duplicated entries {emails.duplicated().sum()}\")\n",
    "\n",
    "#remove Null values\n",
    "print(\"Number of null features in the dataset :\")\n",
    "print(f\"{emails.isnull().sum()}\")\n",
    "\n",
    "print()\n",
    "emails.dropna(subset=[\"X\"], inplace=True)\n",
    "\n",
    "print(\"Number of null features in the dataset :\")\n",
    "print(f\"{emails.isnull().sum()}\")\n",
    "\n",
    "def get_length(text):\n",
    "    lst = text.split()\n",
    "    return len(lst)\n",
    "\n",
    "emails[\"lengths\"] = emails[\"X\"].apply(lambda x: get_length(x))\n",
    "emails.lengths.describe()\n",
    "# sentence_tokenized.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "adaptive-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******** Reporting iteration 0 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 34038)\n",
      "Testing data shape : (1099, 34038)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 1 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 35619)\n",
      "Testing data shape : (1099, 35619)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 2 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36233)\n",
      "Testing data shape : (1099, 36233)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 3 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36438)\n",
      "Testing data shape : (1099, 36438)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 4 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36494)\n",
      "Testing data shape : (1099, 36494)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 0 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 35495)\n",
      "Testing data shape : (1099, 35495)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 1 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36335)\n",
      "Testing data shape : (1099, 36335)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 2 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36488)\n",
      "Testing data shape : (1099, 36488)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 3 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 4 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 0 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36104)\n",
      "Testing data shape : (1099, 36104)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 1 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36476)\n",
      "Testing data shape : (1099, 36476)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 2 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36500)\n",
      "Testing data shape : (1099, 36500)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 3 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 4 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 0 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36329)\n",
      "Testing data shape : (1099, 36329)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 1 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36501)\n",
      "Testing data shape : (1099, 36501)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 2 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 3 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 4 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 0 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36419)\n",
      "Testing data shape : (1099, 36419)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 1 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 2 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 3 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "******** Reporting iteration 4 ********\n",
      "Training split input: (4396,)\n",
      "Testing split input : (1099,)\n",
      "Training split class: (4396,)\n",
      "Testing split class : (1099,)\n",
      "Training data shape : (4396, 36502)\n",
      "Testing data shape : (1099, 36502)\n",
      "Training split class type: <class 'numpy.ndarray'>\n",
      "Testing split class type : <class 'numpy.ndarray'>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[  Threshold  Accuracy  Duration  Number of Words Added\n",
       " 0      25 %  0.987261     15.02                    100\n",
       " 1      30 %  0.986351     12.35                    100\n",
       " 2      20 %  0.985441     15.56                    100\n",
       " 3      35 %  0.985441     17.73                    100\n",
       " 4      40 %  0.982712     24.62                    100,\n",
       "   Threshold  Accuracy  Duration  Number of Words Added\n",
       " 0      20 %  0.985441     13.89                    200\n",
       " 1      30 %  0.984531     28.05                    200\n",
       " 2      25 %  0.983621     18.07                    200\n",
       " 3      35 %  0.982712     33.51                    200\n",
       " 4      40 %  0.971793     41.35                    200,\n",
       "   Threshold  Accuracy  Duration  Number of Words Added\n",
       " 0      25 %  0.983621     24.57                    300\n",
       " 1      20 %  0.982712     16.88                    300\n",
       " 2      30 %  0.982712     32.64                    300\n",
       " 3      35 %  0.979072     44.83                    300\n",
       " 4      40 %  0.974522     66.23                    300,\n",
       "   Threshold  Accuracy  Duration  Number of Words Added\n",
       " 0      20 %  0.987261     21.28                    400\n",
       " 1      25 %  0.982712     36.67                    400\n",
       " 2      30 %  0.981802     79.88                    400\n",
       " 3      35 %  0.981802    110.73                    400\n",
       " 4      40 %  0.973612    100.07                    400,\n",
       "   Threshold  Accuracy  Duration  Number of Words Added\n",
       " 0      20 %  0.984531     32.06                    500\n",
       " 1      25 %  0.982712     46.31                    500\n",
       " 2      30 %  0.979982     76.13                    500\n",
       " 3      35 %  0.978162    100.12                    500\n",
       " 4      40 %  0.970883    115.24                    500]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Adversarial_algorithm(num):   \n",
    "    Poisoned_classifiers = {\n",
    "        \"20 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "        \"25 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "        \"30 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "        \"35 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "        \"40 %\" : {\"model\" :XGBClassifier(eval_metric='mlogloss') , \"train_data\" : 0 , \"y_pred\" : 0 , \"duration\" : 0 , \"accuracy\" : 0 },\n",
    "\n",
    "    }\n",
    "\n",
    "    X_tr = X_train.copy()\n",
    "    #Length_of_Email = [50, 100, 200, 300, 400]\n",
    "    new_entries = []\n",
    "\n",
    "    for i, v in enumerate(Poisoned_classifiers):\n",
    "        list_of_index = idx_all_rand[i]\n",
    "        start = perf_counter()\n",
    "        for j in list_of_index:\n",
    "\n",
    "            if (y_train_np[j] == 1): #Spam\n",
    "                text = X_tr[j]\n",
    "                text = text.split()\n",
    "                Number_of_words_to_add = np.random.randint(0, len(common_ham_words), num)\n",
    "                for k in Number_of_words_to_add:\n",
    "                    #text.append(common_ham_words[k])\n",
    "                    text.insert(randrange(len(text)+1), common_ham_words[k])             \n",
    "\n",
    "                new_text = \" \".join([w for w in text])\n",
    "                X_tr[j] = new_text\n",
    "            else : #Ham\n",
    "\n",
    "                text = X_tr[j]\n",
    "                text = text.split()\n",
    "                Number_of_words_to_add = np.random.randint(0, len(common_spam_words), num)\n",
    "                for k in Number_of_words_to_add:\n",
    "                    #text.append(common_ham_words[k])\n",
    "                    text.insert(randrange(len(text)+1), common_spam_words[k])\n",
    "\n",
    "                new_text = \" \".join([w for w in text])\n",
    "                X_tr[j] = new_text\n",
    "\n",
    "        tf_idf_vectorizer = TfidfVectorizer()\n",
    "        X_train_vect = tf_idf_vectorizer.fit_transform(X_tr)\n",
    "        X_test_vect  = tf_idf_vectorizer.transform(X_test)\n",
    "        X_train_vect.toarray()\n",
    "        X_test_vect.toarray()\n",
    "\n",
    "        print(f\"\\n******** Reporting iteration {i} ********\")\n",
    "        print(f\"Training split input: {X_tr.shape}\")\n",
    "        print(f\"Testing split input : {X_test.shape}\")\n",
    "        print(f\"Training split class: {y_train_np.shape}\")\n",
    "        print(f\"Testing split class : {y_test_np.shape}\")\n",
    "\n",
    "        print(f\"Training data shape : {X_train_vect.shape}\")\n",
    "        print(f\"Testing data shape : {X_test_vect.shape}\")\n",
    "\n",
    "        print(f\"Training split class type: {type(y_train_np)}\")\n",
    "        print(f\"Testing split class type : {type(y_test_np)}\\n\")\n",
    "\n",
    "\n",
    "        Poisoned_classifiers[v][\"model\"].fit(X_train_vect, y_train_np)\n",
    "        test_accuracy = Poisoned_classifiers[v][\"model\"].score(X_test_vect, y_test_np)\n",
    "        y_pred = Poisoned_classifiers[v][\"model\"].predict(X_test_vect)\n",
    "        duration = perf_counter() - start\n",
    "        duration = round(duration,2)\n",
    "        Poisoned_classifiers[v][\"train_data\"] = X_tr\n",
    "        Poisoned_classifiers[v][\"y_pred\"] = y_pred\n",
    "        Poisoned_classifiers[v][\"duration\"] = duration\n",
    "        Poisoned_classifiers[v][\"accuracy\"] = test_accuracy\n",
    "\n",
    "\n",
    "    model_information = []\n",
    "\n",
    "    for percent,model in Poisoned_classifiers.items():\n",
    "        model_information.append([percent, model[\"accuracy\"], model[\"duration\"], num])\n",
    "\n",
    "    info = pd.DataFrame(model_information)\n",
    "    info.columns = [\"Threshold\" , \"Accuracy\", \"Duration\", \"Number of Words Added\"]\n",
    "    info.sort_values(by = 'Accuracy', ascending = False, inplace=True)\n",
    "    info.reset_index(drop = True, inplace=True)\n",
    "    return Poisoned_classifiers, info\n",
    "\n",
    "num_words_per_record = [100,200,300,400,500]\n",
    "Classifiers = {}\n",
    "\n",
    "for i in num_words_per_record:\n",
    "    Poisoned_classifiers, info = Adversarial_algorithm(i)\n",
    "    Classifiers[f\"{i}\"] = {f\"Poisoned_classifiers\" : Poisoned_classifiers, \"info\" : info}\n",
    "\n",
    "# Merge = [\n",
    "#     Classifiers[\"100\"][\"info\"],\n",
    "#     Classifiers[\"200\"][\"info\"],\n",
    "#     Classifiers[\"300\"][\"info\"],\n",
    "#     Classifiers[\"400\"][\"info\"],\n",
    "#     Classifiers[\"500\"][\"info\"]\n",
    "# ]\n",
    "merge = []\n",
    "\n",
    "for i,v in enumerate(Classifiers):\n",
    "    \n",
    "    merge.append(Classifiers[v][\"info\"])\n",
    "    \n",
    "merge  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "under-projector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Number of Words Added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25 %</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>15.02</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20 %</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>21.28</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 %</td>\n",
       "      <td>0.986351</td>\n",
       "      <td>12.35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20 %</td>\n",
       "      <td>0.985441</td>\n",
       "      <td>15.56</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35 %</td>\n",
       "      <td>0.985441</td>\n",
       "      <td>17.73</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20 %</td>\n",
       "      <td>0.985441</td>\n",
       "      <td>13.89</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30 %</td>\n",
       "      <td>0.984531</td>\n",
       "      <td>28.05</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20 %</td>\n",
       "      <td>0.984531</td>\n",
       "      <td>32.06</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25 %</td>\n",
       "      <td>0.983621</td>\n",
       "      <td>18.07</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25 %</td>\n",
       "      <td>0.983621</td>\n",
       "      <td>24.57</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25 %</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>46.31</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25 %</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>36.67</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30 %</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>32.64</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20 %</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>16.88</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35 %</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>33.51</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40 %</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>24.62</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30 %</td>\n",
       "      <td>0.981802</td>\n",
       "      <td>79.88</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>35 %</td>\n",
       "      <td>0.981802</td>\n",
       "      <td>110.73</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30 %</td>\n",
       "      <td>0.979982</td>\n",
       "      <td>76.13</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>35 %</td>\n",
       "      <td>0.979072</td>\n",
       "      <td>44.83</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35 %</td>\n",
       "      <td>0.978162</td>\n",
       "      <td>100.12</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40 %</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>66.23</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40 %</td>\n",
       "      <td>0.973612</td>\n",
       "      <td>100.07</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40 %</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>41.35</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40 %</td>\n",
       "      <td>0.970883</td>\n",
       "      <td>115.24</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  Accuracy  Duration  Number of Words Added\n",
       "0       25 %  0.987261     15.02                    100\n",
       "1       20 %  0.987261     21.28                    400\n",
       "2       30 %  0.986351     12.35                    100\n",
       "3       20 %  0.985441     15.56                    100\n",
       "4       35 %  0.985441     17.73                    100\n",
       "5       20 %  0.985441     13.89                    200\n",
       "6       30 %  0.984531     28.05                    200\n",
       "7       20 %  0.984531     32.06                    500\n",
       "8       25 %  0.983621     18.07                    200\n",
       "9       25 %  0.983621     24.57                    300\n",
       "10      25 %  0.982712     46.31                    500\n",
       "11      25 %  0.982712     36.67                    400\n",
       "12      30 %  0.982712     32.64                    300\n",
       "13      20 %  0.982712     16.88                    300\n",
       "14      35 %  0.982712     33.51                    200\n",
       "15      40 %  0.982712     24.62                    100\n",
       "16      30 %  0.981802     79.88                    400\n",
       "17      35 %  0.981802    110.73                    400\n",
       "18      30 %  0.979982     76.13                    500\n",
       "19      35 %  0.979072     44.83                    300\n",
       "20      35 %  0.978162    100.12                    500\n",
       "21      40 %  0.974522     66.23                    300\n",
       "22      40 %  0.973612    100.07                    400\n",
       "23      40 %  0.971793     41.35                    200\n",
       "24      40 %  0.970883    115.24                    500"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merged = pd.concat(merge)\n",
    "Merged.sort_values(by = 'Accuracy', ascending = False, inplace=True)\n",
    "Merged.reset_index(drop = True, inplace=True)\n",
    "Merged.to_csv(\"comparison/Spam_Ham_Injection_Adversarial.csv\")\n",
    "Merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-generation",
   "metadata": {},
   "source": [
    "# Algorithm 3: Addition of New Poisoned Entries Algorithm.\n",
    "\n",
    "```C\n",
    "Parameters: threshold, Ham_words, i=1, newEntries = [], Spam_words\n",
    "Number_of_words_to_add = random.randint(Mean_Length_of_Email, 10)\n",
    "\n",
    "Input: Dataset D = (xi,yi) , i = [10% of all training data, 15%, 20%, 25%, 30%];\n",
    "\n",
    "for i in threshold:\n",
    "    Number_of_records_to_add = round(len(xi) * i / 100)\n",
    "    new_entry = []\n",
    "    for j in Number_of_records_to_add:\n",
    "    \n",
    "        for k in Number_of_words_to_add:\n",
    "            word_index = random.randint(len(Ham_words), k)\n",
    "            \n",
    "            new_email = []\n",
    "            \n",
    "            for l in word_index:\n",
    "                new_email.append(l)\n",
    "            new_entry.append(new_email)\n",
    "    newEntries.append(new_entry)\n",
    "\n",
    "Output: newEntries;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "adopted-regard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "No_of_spam = y_train.value_counts()[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-valuable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "arranged-dayton",
   "metadata": {},
   "source": [
    "# **Algorithm 4: Defence Algorithm.**\n",
    "\n",
    "```C\n",
    "\n",
    "Parameters: k=5, malicious_samples = 0;\n",
    "\n",
    "Input: training set T = xi,yi , 1 <= i <= m;\n",
    "\n",
    "for ( i = 1; i <= m; i = i + 1 ) {\n",
    "    \n",
    "    Di = k-NN (Ti ,T)\n",
    "    vote = label_voting (Di)\n",
    "    confidence = vote_confidence (Di,vote)\n",
    "    if confidence > 0.60 and vote != Ti then\n",
    "        malicious_samples++\n",
    "    end\n",
    "        \n",
    "}\n",
    "\n",
    "Output: malicious_samples;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-cleanup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-peripheral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-peeing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-region",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "experienced-sport",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
